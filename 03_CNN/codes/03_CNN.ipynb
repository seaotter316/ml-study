{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 938\n",
      "Number of test batches: 157\n",
      "Batch image shape: torch.Size([64, 1, 28, 28])\n",
      "Batch label shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor() \n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False, \n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of test batches:\", len(test_loader))\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(\"Batch image shape:\", images.shape)\n",
    "    print(\"Batch label shape:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692df0b0",
   "metadata": {},
   "source": [
    "## Model: SimpleCNN\n",
    "Architecture:\n",
    "- `Conv2d(1→16, k3, p1) → ReLU → MaxPool2d(2)`\n",
    "- `Conv2d(16→32, k3, p1) → ReLU → MaxPool2d(2)`\n",
    "- `Flatten → Linear(32*7*7→128) → ReLU → Linear(128→10)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # (B,1,28,28) -> (B,16,28,28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # -> (B,16,14,14)\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # -> (B,32,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                              # -> (B,32,7,7)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                                # -> (B, 32*7*7)\n",
    "            nn.Linear(32 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3a236",
   "metadata": {},
   "source": [
    "### Forward test\n",
    "모델을 완성했다면 아래 셀에서 **output shape = (4, 10)** 이 나와야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5553d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "x = torch.randn(4, 1, 28, 28, device=device)\n",
    "y = model(x)\n",
    "print(\"output:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss / Optimizer\n",
    "- 분류(0~9) → `CrossEntropyLoss`\n",
    "- 기본 optimizer → `Adam`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1e55a",
   "metadata": {},
   "source": [
    "## Train loop (2~3 epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 216.0460 | Train Acc: 0.9283\n",
      "Epoch 2/3 | Loss: 58.3401 | Train Acc: 0.9807\n",
      "Epoch 3/3 | Loss: 40.9252 | Train Acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec85d3",
   "metadata": {},
   "source": [
    "## Test evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(\"Test Acc:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56141a00",
   "metadata": {},
   "source": [
    "## 오답 1개 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "mis = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        wrong = (preds != labels).nonzero(as_tuple=False)\n",
    "        if len(wrong) > 0:\n",
    "            idx = wrong[0].item()\n",
    "            mis = (images[idx].detach().cpu(), int(labels[idx].cpu()), int(preds[idx].cpu()))\n",
    "            break\n",
    "\n",
    "if mis is None:\n",
    "    print(\"No misclassified sample found (unlikely).\")\n",
    "else:\n",
    "    img, y_true, y_pred = mis\n",
    "    plt.figure()\n",
    "    plt.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "    plt.title(f\"True: {y_true} | Pred: {y_pred}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
