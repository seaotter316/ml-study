{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86d6b0c",
   "metadata": {},
   "source": [
    "# Week 3 Assignment — MNIST MLP 실험 (TODO 포함)\n",
    "\n",
    "이 노트북은 3주차 과제를 **그대로 수행**할 수 있도록 구성된 TODO 버전입니다.\n",
    "\n",
    "## 과제 목표\n",
    "- MNIST 분류를 위한 **MLP**를 직접 구현한다.\n",
    "- **Dropout 유무(A/B)** 비교로 Overfitting/Generalization 감각을 얻는다.\n",
    "- **Optimizer(Adam vs SGD)** 비교로 수렴/성능 차이를 관찰한다.\n",
    "- 모델 **파라미터 수**를 코드/손계산으로 확인한다.\n",
    "\n",
    "> ⚠️ `# TODO:`가 있는 부분은 직접 채우세요.  \n",
    "> ✅ “정확도 높이기”가 목표가 아니라, **실험 → 관찰 → 해석**이 목표입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c4c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# (선택) 재현성\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44776343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6505686",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비 (MNIST)\n",
    "\n",
    "- `train=True`: 학습용(60,000)\n",
    "- `train=False`: 테스트용(10,000)\n",
    "\n",
    "전처리는 3주차 MLP 기준으로 **ToTensor()만** 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6aefad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# TODO: 필요하면 batch_size를 바꿔 실험해보세요.\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Test size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b840d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([64, 1, 28, 28])\n",
      "labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# 배치 모양 확인\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"images shape:\", images.shape)  # (B, 1, 28, 28)\n",
    "print(\"labels shape:\", labels.shape)  # (B,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a8133",
   "metadata": {},
   "source": [
    "## 2) 모델 구현 (TODO)\n",
    "\n",
    "아래 두 모델을 구현하세요.\n",
    "\n",
    "- **Model A**: Dropout 없음 (기본 MLP)\n",
    "- **Model B**: Dropout(p=0.3) 포함\n",
    "\n",
    "> 힌트: 입력은 (B, 1, 28, 28)이므로 MLP에 넣으려면 **flatten**이 필요합니다.  \n",
    "> 예) `x = x.view(x.size(0), -1)` 또는 `nn.Flatten()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712e4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTMLP_NoDropout(nn.Module):\n",
    "    def __init__(self, hidden1=256, hidden2=128):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)          # (B, 1, 28, 28) -> (B, 784)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)              # logits (softmax는 CrossEntropyLoss 내부에서 처리)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d808f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTMLP_Dropout(nn.Module):\n",
    "    def __init__(self, hidden1=256, hidden2=128, p=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden2, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade2023",
   "metadata": {},
   "source": [
    "## 3) 학습/평가 함수 (TODO)\n",
    "\n",
    "- `train_one_epoch`: `model.train()` + (zero_grad → forward → loss → backward → step)\n",
    "- `evaluate`: `model.eval()` + `@torch.no_grad()` (forward만)\n",
    "\n",
    "> Loss는 기본적으로 **배치 평균**이라서, epoch 평균 loss를 정확히 구하려면  \n",
    "> `running_loss += loss.item() * batch_size` 후 `running_loss / total_samples`를 사용하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3aba49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "\n",
    "        _, predicted = outputs.max(dim=1)\n",
    "        total += batch_size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d7e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "\n",
    "        _, predicted = outputs.max(dim=1)\n",
    "        total += batch_size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea24654",
   "metadata": {},
   "source": [
    "## 4) 실험 1 — Dropout 유무 비교 (필수)\n",
    "\n",
    "아래 셀을 완성해서 **Model A(무 Dropout)** vs **Model B(Dropout p=0.3)** 를 비교하세요.\n",
    "\n",
    "- Epoch: 3~5\n",
    "- Optimizer: 우선 Adam 또는 SGD 중 하나 고정\n",
    "- 기록: 각 모델의 Train/Test Loss/Acc\n",
    "\n",
    "> Tip: 실험을 깔끔히 하려면 **모델/옵티마이저를 새로 생성**하고 돌리세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904d2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, train_loader, test_loader, optimizer, criterion, device, num_epochs=3):\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"test_loss\"].append(test_loss)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2cc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model A (No Dropout) ===\n",
      "Epoch [1/3] Train Loss: 0.2884, Train Acc: 0.9161 | Test Loss: 0.1412, Test Acc: 0.9558\n",
      "Epoch [2/3] Train Loss: 0.1109, Train Acc: 0.9666 | Test Loss: 0.1028, Test Acc: 0.9681\n",
      "Epoch [3/3] Train Loss: 0.0741, Train Acc: 0.9767 | Test Loss: 0.0732, Test Acc: 0.9772\n"
     ]
    }
   ],
   "source": [
    "# 공통 설정\n",
    "num_epochs = 3\n",
    "\n",
    "# Loss 함수(분류)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------------\n",
    "# Model A: Dropout 없음\n",
    "# -------------------------\n",
    "model_a = MNISTMLP_NoDropout(hidden1=256, hidden2=128).to(device)\n",
    "\n",
    "# Optimizer (비교 공정성을 위해 exp1에서는 동일 설정 사용)\n",
    "optimizer_a = optim.Adam(model_a.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"=== Model A (No Dropout) ===\")\n",
    "hist_a = run_experiment(model_a, train_loader, test_loader, optimizer_a, criterion, device, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada12216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model B (Dropout p=0.3) ===\n",
      "Epoch [1/3] Train Loss: 0.3209, Train Acc: 0.9057 | Test Loss: 0.1368, Test Acc: 0.9582\n",
      "Epoch [2/3] Train Loss: 0.1397, Train Acc: 0.9575 | Test Loss: 0.1059, Test Acc: 0.9673\n",
      "Epoch [3/3] Train Loss: 0.1019, Train Acc: 0.9687 | Test Loss: 0.0826, Test Acc: 0.9749\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Model B: Dropout(p=0.3)\n",
    "# -------------------------\n",
    "model_b = MNISTMLP_Dropout(hidden1=256, hidden2=128, p=0.3).to(device)\n",
    "\n",
    "# Optimizer는 A와 동일하게 (공정 비교)\n",
    "optimizer_b = optim.Adam(model_b.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"=== Model B (Dropout p=0.3) ===\")\n",
    "hist_b = run_experiment(model_b, train_loader, test_loader, optimizer_b, criterion, device, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4592d",
   "metadata": {},
   "source": [
    "### ✍️ 실험 1 서술 (필수)\n",
    "\n",
    "아래 질문에 **5~7줄**로 답하세요.\n",
    "\n",
    "1. Train Accuracy는 A/B 중 어느 쪽이 더 높았나요?  \n",
    "2. Test Accuracy는 A/B 중 어느 쪽이 더 안정적이었나요?  \n",
    "3. 이를 **Overfitting / Generalization** 관점에서 어떻게 해석하나요?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4faeb",
   "metadata": {},
   "source": [
    "(여기에 답을 작성하세요)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cead96",
   "metadata": {},
   "source": [
    "## 5) 실험 2 — Optimizer 비교 (필수)\n",
    "\n",
    "같은 모델 구조에서 Optimizer만 바꿔 비교하세요.\n",
    "\n",
    "- Optimizer A: Adam (권장 lr=1e-3)\n",
    "- Optimizer B: SGD (권장 lr=0.1)\n",
    "- Epoch: 1~3\n",
    "\n",
    "> Tip: 비교를 위해 **같은 모델 구조**를 사용하세요. (Dropout 없는 A 모델 추천)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06188d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimizer: Adam ===\n",
      "Epoch [1/1] Train Loss: 0.2786, Train Acc: 0.9192 | Test Loss: 0.1333, Test Acc: 0.9585\n",
      "\n",
      "=== Optimizer: SGD ===\n",
      "Epoch [1/1] Train Loss: 0.4891, Train Acc: 0.8633 | Test Loss: 0.2349, Test Acc: 0.9266\n"
     ]
    }
   ],
   "source": [
    "# 실험 2 설정\n",
    "num_epochs_opt = 1  # 1~3으로 조절해도 OK\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 같은 구조의 새 모델 생성 (Dropout 없는 모델로 비교)\n",
    "model_opt_adam = MNISTMLP_NoDropout(hidden1=256, hidden2=128).to(device)\n",
    "model_opt_sgd = MNISTMLP_NoDropout(hidden1=256, hidden2=128).to(device)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer_adam = optim.Adam(model_opt_adam.parameters(), lr=1e-3)\n",
    "\n",
    "# SGD optimizer\n",
    "optimizer_sgd = optim.SGD(model_opt_sgd.parameters(), lr=0.1)\n",
    "\n",
    "print(\"=== Optimizer: Adam ===\")\n",
    "hist_adam = run_experiment(model_opt_adam, train_loader, test_loader, optimizer_adam, criterion, device, num_epochs=num_epochs_opt)\n",
    "\n",
    "print(\"\\n=== Optimizer: SGD ===\")\n",
    "hist_sgd = run_experiment(model_opt_sgd, train_loader, test_loader, optimizer_sgd, criterion, device, num_epochs=num_epochs_opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad980dc",
   "metadata": {},
   "source": [
    "### ✍️ 실험 2 서술 (필수)\n",
    "\n",
    "아래 질문에 **4~6줄**로 답하세요.\n",
    "\n",
    "1. 1 epoch(또는 초반) 기준으로 loss 감소가 더 빨랐던 쪽은?  \n",
    "2. accuracy 변화는 어땠나요?  \n",
    "3. “실전에서 하나만 고르라면?” 본인의 선택 기준은?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53acc1",
   "metadata": {},
   "source": [
    "(여기에 답을 작성하세요)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6321557b",
   "metadata": {},
   "source": [
    "## 6) 파라미터 개수 분석 (필수)\n",
    "\n",
    "### (1) 코드로 세기\n",
    "- `sum(p.numel() for p in model.parameters())`\n",
    "\n",
    "### (2) 손으로 계산\n",
    "- Linear(784, 256): 784×256 + 256  \n",
    "- Linear(256, 128): 256×128 + 128  \n",
    "- Linear(128, 10): 128×10 + 10  \n",
    "\n",
    "> 어떤 레이어가 파라미터를 가장 많이 쓰는지 확인하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c9f961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 235146\n",
      "fc1.weight [256, 784] 200704\n",
      "fc1.bias [256] 256\n",
      "fc2.weight [128, 256] 32768\n",
      "fc2.bias [128] 128\n",
      "fc3.weight [10, 128] 1280\n",
      "fc3.bias [10] 10\n"
     ]
    }
   ],
   "source": [
    "# 분석할 모델 선택 (예: model_a 또는 model_b 등)\n",
    "# 여기서는 Model A를 기본으로 사용합니다.\n",
    "model_for_params = model_a\n",
    "\n",
    "total_params = sum(p.numel() for p in model_for_params.parameters())\n",
    "print(\"Total parameters:\", total_params)\n",
    "\n",
    "# (선택) 레이어별 파라미터 수 보기\n",
    "for name, p in model_for_params.named_parameters():\n",
    "    print(name, list(p.shape), p.numel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460936f",
   "metadata": {},
   "source": [
    "### ✍️ 파라미터 분석 서술 (필수)\n",
    "\n",
    "아래 질문에 **4~6줄**로 답하세요.\n",
    "\n",
    "1. 코드로 센 파라미터 수는 얼마인가요?  \n",
    "2. 손계산 결과(각 레이어 + 합계)는 어떻게 되나요?  \n",
    "3. 파라미터 수가 커지면 장점/단점은? (표현력↑ / 과적합↑ / 계산량↑ 등)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fe285",
   "metadata": {},
   "source": [
    "(여기에 답을 작성하세요)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e53d25",
   "metadata": {},
   "source": [
    "## 7) (선택) 자유 실험\n",
    "\n",
    "아래 중 1개 이상 선택해 간단히 결과를 남기세요.\n",
    "- Dropout p를 0.1 / 0.5로 바꿔보기\n",
    "- hidden 크기 64/128/256/512 바꿔보기\n",
    "- epoch 늘려서 Train/Test 차이 관찰\n",
    "- 틀린 샘플 5개 시각화\n",
    "\n",
    "(선택 과제는 짧게만 기록해도 됩니다.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
