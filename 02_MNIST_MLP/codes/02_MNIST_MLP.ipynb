{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe19646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d3180",
   "metadata": {},
   "source": [
    "# 1. MNIST 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72324e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # 이미지->Tensor 변환 ([0,255] → [0,1](정규화), shape: (1, 28, 28))\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', # 상대 경로 (현재 디렉토리 기준)에 data 폴더 생성 및 데이터 저장\n",
    "    train=True, # MNIST에서 학습용 데이터 가져오기\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False, # MNIST에서 테스트용 데이터 가져오기\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27ec5836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46cbd90",
   "metadata": {},
   "source": [
    "대충 하나 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93a60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([1, 28, 28])\n",
      "label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = train_dataset[15]\n",
    "\n",
    "print(\"image shape:\", image.shape)\n",
    "print(\"label:\", label)\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray') # 몰라도 됩니다\n",
    "plt.show() # 몰라도 됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac8356",
   "metadata": {},
   "source": [
    "# 2. DataLoader로 배치별로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68bb605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 938\n",
      "Number of test batches: 157\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a7f5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch image shape: torch.Size([64, 1, 28, 28])\n",
      "Batch label shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(\"Batch image shape:\", images.shape)\n",
    "    print(\"Batch label shape:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298ae93",
   "metadata": {},
   "source": [
    "# 3. MLP 모델 구조화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d466c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 정의 (nn.Sequential 미사용)\n",
    "\n",
    "class MNISTMLP_noSequential(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Layer 정의\n",
    "        self.fc1 = nn.Linear(28 * 28, 256) # 첫 번째 은닉층, 784 → 256\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128) # 두 번째 은닉층, 256 → 128\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 10)  # 출력층, softmax는 이미 nn.CrossEntropyLoss()에 포함되어 있음\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1, 28, 28) → (batch, 784) 변환(flatten)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Layer를 순서대로 적용\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f231b53",
   "metadata": {},
   "source": [
    "nn.Sequential을 안 쓰면 코드가 과하게 길어지고 가독성이 떨어진다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1dc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 정의 (nn.Sequential 사용)\n",
    "\n",
    "class MNISTMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb1c1238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a6930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTMLP().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()      # 분류 국룰\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f957a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 epoch 학습 함수\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train() # 모델을 학습 모드로 설정: Dropout, BatchNorm 등 학습 모드로 설정(하지만 여기서는 Dropout, BatchNorm 안 써서 영향 없음)\n",
    "    total_loss = 0.0 # 누적 손실\n",
    "    correct = 0 # 맞춘 개수\n",
    "    total = 0 # 전체 개수\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device) # 입력 이미지 텐서를 device(GPU 또는 CPU)로 이동\n",
    "        labels = labels.to(device) # 레이블 텐서를 device(GPU 또는 CPU)로 이동\n",
    "\n",
    "        # 1. gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. forward\n",
    "        outputs = model(images)          # shape: (batch, 10)\n",
    "\n",
    "        # 3. loss 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 4. backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. update\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. 통계\n",
    "        total_loss += loss.item() * images.size(0) # 배치 손실에 배치 크기 곱해서 누적\n",
    "        _, predicted = outputs.max(dim = 1)    # 1번째 dimension에서 최대값의 값과 인덱스 추출(그러나 값은 사용X)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = total_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1da63587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 epoch 평가 함수\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval() # 모델을 평가 모드로 설정\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 1. forward\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 2. loss 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c824e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Train Loss: 0.4842, Train Acc: 0.8598 | Test Loss: 0.2216, Test Acc: 0.9322\n",
      "Epoch [2/5] Train Loss: 0.1827, Train Acc: 0.9463 | Test Loss: 0.1472, Test Acc: 0.9546\n",
      "Epoch [3/5] Train Loss: 0.1221, Train Acc: 0.9643 | Test Loss: 0.1114, Test Acc: 0.9654\n",
      "Epoch [4/5] Train Loss: 0.0903, Train Acc: 0.9731 | Test Loss: 0.0965, Test Acc: 0.9695\n",
      "Epoch [5/5] Train Loss: 0.0714, Train Acc: 0.9788 | Test Loss: 0.0864, Test Acc: 0.9722\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n",
    "        f\"| Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d1bc2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 235146\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
